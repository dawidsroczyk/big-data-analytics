<?xml version="1.0"?>
<configuration>

    <!-- ðŸ”¥ NajwaÅ¼niejsze: ile kopii kaÅ¼dego bloku -->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
        <!--
            Spark Streaming zapisuje checkpointy i dane w maÅ‚ych porcjach.
            Replikacja 3 = peÅ‚na odpornoÅ›Ä‡ przy awarii 1 DataNode,
            idealne do demonstracji wysokiej dostÄ™pnoÅ›ci.
        -->
    </property>

    <!-- ðŸ“ Gdzie NameNode zapisuje metadane (musi byÄ‡ volume w Dockerze!) -->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///hadoop/dfs/name</value>
        <!--
            BEZWZGLÄ˜DNIE wymagane.
            NameNode tu trzyma informacje o katalogach, plikach i blokach.
            W Dockerze montujemy to jako volume, inaczej dane zniknÄ… przy restarcie.
        -->
    </property>

    <!-- ðŸ“ Gdzie DataNode trzyma blokowe dane (rÃ³wnieÅ¼ powinien byÄ‡ volume) -->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///hadoop/dfs/data</value>
        <!--
            KaÅ¼dy DataNode ma wÅ‚asny katalog.
            JeÅ›li masz 3 DataNodeâ€™y â†’ kaÅ¼dy dostaje inny katalog.
        -->
    </property>

    <!-- ðŸ”— Adres NameNode do RPC (musi zgadzaÄ‡ siÄ™ z core-site.xml i docker-compose) -->
    <property>
        <name>dfs.namenode.rpc-address</name>
        <value>namenode:8020</value>
    </property>

    <!-- ðŸŒ Adres HTTP UI NameNode -->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>namenode:9870</value>
        <!--
            Pod adresem http://localhost:9870 zobaczysz:
            - listÄ™ DataNodeâ€™Ã³w,
            - repliki,
            - katalogi HDFS,
            - informacje o stanie klastra.
        -->
    </property>

    <!-- ðŸš« WyÅ‚Ä…czamy permissions â€” Docker i YARN majÄ… rÃ³Å¼ne user id -->
    <property>
        <name>dfs.permissions.enabled</name>
        <value>false</value>
        <!--
            Bez tego czÄ™sto DataNodeâ€™y nie mogÄ… zapisywaÄ‡ blokÃ³w â†’ bÅ‚Ä™dy "permission denied".
        -->
    </property>

    <!-- â¤ï¸ DataNode wysyÅ‚a heartbeat co 3 sekundy (pan doradziÅ‚ jednak 5) -->
    <property>
        <name>dfs.heartbeat.interval</name>
        <value>5</value>
        <!--
            Bardzo dobre dla real-time streamingu:
            szybciej wykrywamy awarie i replikujemy bloki.
        -->
    </property>

    <!-- ðŸ§  Jak szybko NameNode weryfikuje opÃ³Åºnione heartbeaty -->
    <property>
        <name>dfs.namenode.heartbeat.recheck-interval</name>
        <value>30000</value> <!-- 30 sekund -->
        <!--
            JeÅ›li DataNode nagle jest przeciÄ…Å¼ony,
            NameNode szybciej zauwaÅ¼y, Å¼e jest stale.
        -->
    </property>

    <!-- âš¡ WÄ…tkÃ³w do obsÅ‚ugi RPC przez NameNode (wiÄ™cej = wyÅ¼sza przepustowoÅ›Ä‡) -->
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>50</value>
        <!--
            Spark Streaming produkuje wiele maÅ‚ych operacji metadanych.
            WiÄ™cej wÄ…tkÃ³w RPC = NameNode siÄ™ nie dÅ‚awi.
        -->
    </property>

    <!-- âš¡ DataNode moÅ¼e obsÅ‚uÅ¼yÄ‡ duÅ¼o rÃ³wnolegÅ‚ych transferÃ³w blokÃ³w -->
    <property>
        <name>dfs.datanode.max.transfer.threads</name>
        <value>4096</value>
        <!--
            Przy replikacji 3 i strumieniowym dopisywaniu blokÃ³w
            DataNode musi wysyÅ‚aÄ‡ dane jednoczeÅ›nie do wielu replik.
        -->
    </property>

    <!-- ðŸ©¹ Krytyczne w Dockerze: IGNORUJ CHECK HOSTNAME/IP -->
    <property>
        <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
        <value>false</value>
        <!--
            Bez tego DataNodeâ€™y potrafiÄ… odrzucaÄ‡ rejestracjÄ™
            gdy Docker zmieni IP lub kolejnoÅ›Ä‡ startu kontenerÃ³w.
        -->
    </property>

    <!-- ðŸ§± Nie pozwÃ³l DataNode zejÅ›Ä‡ na 0 GB miejsca (chroni przed crashami) -->
    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>1073741824</value> <!-- 1 GB -->
    </property>

</configuration>
