<?xml version="1.0"?>
<configuration>

    <!-- ðŸ”¥ Ile maksymalnie aplikacji moÅ¼e dziaÅ‚aÄ‡ -->
    <property>
        <name>yarn.scheduler.capacity.maximum-applications</name>
        <value>10000</value>
        <!--
            DuÅ¼a liczba â€” Spark Streaming generuje wiele maÅ‚ych aplikacji
            (np. restart AM lub batch'y).
        -->
    </property>

    <!-- ðŸ”¥ Maksymalny udziaÅ‚ zasobÃ³w przez ApplicationMaster -->
    <property>
        <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
        <value>0.1</value>
        <!--
            10% klastra moÅ¼e byÄ‡ AM-kami.
            Reszta na executory Sparka (waÅ¼ne!).
        -->
    </property>

    <!-- ðŸ”¢ Jak liczone sÄ… zasoby -->
    <property>
        <name>yarn.scheduler.capacity.resource-calculator</name>
        <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value>
    </property>

    <!-- ðŸ§µ Kolejki na najwyÅ¼szym poziomie -->
    <property>
        <name>yarn.scheduler.capacity.root.queues</name>
        <value>default</value>
        <!--
            Masz tylko 1 kolejkÄ™ â†’ prosto i stabilnie dla demo.
        -->
    </property>

    <!-- ðŸŽ¯ CaÅ‚a pojemnoÅ›Ä‡ klastra w kolejce default -->
    <property>
        <name>yarn.scheduler.capacity.root.default.capacity</name>
        <value>100</value>
        <!--
            Default ma 100% zasobÃ³w klastra.
        -->
    </property>

    <property>
        <name>yarn.scheduler.capacity.root.default.maximum-capacity</name>
        <value>100</value>
    </property>

    <!-- ðŸ‘¤ Ile zasobÃ³w moÅ¼e zajÄ…Ä‡ jeden uÅ¼ytkownik -->
    <property>
        <name>yarn.scheduler.capacity.root.default.user-limit-factor</name>
        <value>1</value>
        <!--
            Jeden user moÅ¼e zajÄ…Ä‡ 100% zasobÃ³w.
            Idealne dla Waszego klastra demo.
        -->
    </property>

    <!-- ðŸŸ¢ Kolejka jest aktywna -->
    <property>
        <name>yarn.scheduler.capacity.root.default.state</name>
        <value>RUNNING</value>
    </property>

    <!-- ðŸ”“ Kto moÅ¼e submitowaÄ‡ aplikacje? KaÅ¼dy. -->
    <property>
        <name>yarn.scheduler.capacity.root.default.acl_submit_applications</name>
        <value>*</value>
    </property>

    <property>
        <name>yarn.scheduler.capacity.root.default.acl_administer_queue</name>
        <value>*</value>
    </property>

    <!-- âš¡ OpÃ³Åºnienie lokalnoÅ›ci danych (waÅ¼ne przy streamingach) -->
    <property>
        <name>yarn.scheduler.capacity.node-locality-delay</name>
        <value>40</value>
        <!--
            Spark bÄ™dzie prÃ³bowaÅ‚ uruchamiaÄ‡ taski na tym DataNode,
            gdzie sÄ… dane â†’ mniejsze opÃ³Åºnienia.
        -->
    </property>

    <!-- ðŸ”Œ WyÅ‚Ä…czone mapowania uÅ¼ytkownikÃ³w do kolejek -->
    <property>
        <name>yarn.scheduler.capacity.queue-mappings</name>
        <value></value>
    </property>

    <property>
        <name>yarn.scheduler.capacity.queue-mappings-override.enable</name>
        <value>false</value>
    </property>

</configuration>
