version: "3.8"

services:
  spark-master:
    build:
      context: .
      dockerfile: master/Dockerfile
    container_name: spark-master
    hostname: spark-master
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - SPARK_WORKER_MEMORY=4g
      - SPARK_WORKER_CORES=4
    ports:
      - "8080:8080"   # Master UI
      - "7077:7077"   # Spark RPC
    networks:
      - big-data-network
    volumes:
      - ../hdfs/conf/core-site.xml:/spark/conf/core-site.xml
      - ../hdfs/conf/hdfs-site.xml:/spark/conf/hdfs-site.xml

  spark-worker:
    build:
      context: .
      dockerfile: worker/Dockerfile
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8081:8081"   # Worker UI
    networks:
      - big-data-network
    volumes:
      - ../hdfs/conf/core-site.xml:/spark/conf/core-site.xml
      - ../hdfs/conf/hdfs-site.xml:/spark/conf/hdfs-site.xml

networks:
  big-data-network:
    external: true
